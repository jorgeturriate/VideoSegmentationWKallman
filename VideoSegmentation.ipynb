{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn3WIiglpA/iHGHBILlB5v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgeturriate/VideoSegmentationWKallman/blob/main/VideoSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Segmentation"
      ],
      "metadata": {
        "id": "clcgGIT6D-Gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firt, we need to perform object detection of the Tennis ball to use it as an input for the Kalman filter which will use these detections to predict the trayectory of the Tennis ball.\n",
        "I tried first with Yolo v8, but the results using YoloV5 were better, so I changed to YoloV5."
      ],
      "metadata": {
        "id": "NTzLssxETxhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install git+https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "id": "m9PurhYqTrdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing library"
      ],
      "metadata": {
        "id": "Qb4Y9yjpGcmP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRGa0TTvC3IN"
      },
      "outputs": [],
      "source": [
        "#from ultralytics import YOLO\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "video_path = \"/content/drive/My Drive/VideoSegmentation/RogerVideo.mp4\"  # Update this with your actual video path"
      ],
      "metadata": {
        "id": "n6nkny8nEAbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_video_path = \"/content/drive/My Drive/VideoSegmentation/segmented_video_output.mp4\"\n",
        "\n",
        "# Load YOLOv5 model (you can use 'yolov5s' or a different model depending on your needs)\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # Pre-trained YOLOv8 Nano model"
      ],
      "metadata": {
        "id": "h7jeYOdHL9jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I got the HSV values for the Tennis ball and I'm using these values to set the range of the HSV values to improve the detection of the YOLOv5."
      ],
      "metadata": {
        "id": "JXRAVegB47i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the HSV range for the tennis ball (you can fine-tune these values)\n",
        "lower_hsv = np.array([80, 50, 150])  # Lower bound for greenish tennis balls\n",
        "upper_hsv = np.array([100, 255, 255])  # Upper bound for greenish tennis balls"
      ],
      "metadata": {
        "id": "9oGgApc2hcSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the initial features of the video."
      ],
      "metadata": {
        "id": "XP-MwZrtJCWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "print(f\"Original Video Properties -> Width: {frame_width}, Height: {frame_height}, FPS: {fps}\")"
      ],
      "metadata": {
        "id": "BO8buxHTJBre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the output video settings"
      ],
      "metadata": {
        "id": "TKdS6Mn0JV3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))"
      ],
      "metadata": {
        "id": "5LeOzHVAJUgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing Kalman filter to follow the trayectory of the ball."
      ],
      "metadata": {
        "id": "WJizCp90MMmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Kalman Filter\n",
        "kalman = cv2.KalmanFilter(4, 2)  # 4 states (x, y, vx, vy), 2 measurements (x, y)\n",
        "kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
        "kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
        "kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03\n"
      ],
      "metadata": {
        "id": "yLZihlV6neXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segmenting the video, we can see also the velocity of the ball inside the frames we are creating and the trayectory the ball was following by using the predictions of the Kalman filter."
      ],
      "metadata": {
        "id": "JEe_9ajDJnpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame_count = 0\n",
        "trajectory = []  # To store the trajectory of the ball\n",
        "initial_kalman_initialized = False\n",
        "last_position = None\n",
        "last_time = 0\n",
        "speed = 0  # Initial speed"
      ],
      "metadata": {
        "id": "Opx1BTB8nihO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"End of video.\")\n",
        "        break\n",
        "\n",
        "    # Convert frame to HSV for color-based segmentation\n",
        "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Create mask for tennis ball in HSV range\n",
        "    mask = cv2.inRange(hsv_frame, lower_hsv, upper_hsv)\n",
        "\n",
        "    # Perform YOLOv5 detection on the frame\n",
        "    results = model(frame)\n",
        "\n",
        "    # Process YOLOv5 detections\n",
        "    detected_ball = None\n",
        "    for result in results.xywh[0]:  # Format: [x_center, y_center, width, height, confidence, class_id]\n",
        "        x_center, y_center, w, h, conf, cls = result.tolist()\n",
        "        if int(cls) == 32:  # Replace with the class ID for 'tennis ball' (check with your model)\n",
        "            detected_ball = (int(x_center), int(y_center))\n",
        "\n",
        "    # Initialize Kalman Filter with the first detected ball position\n",
        "    if detected_ball and not initial_kalman_initialized:\n",
        "        kalman.statePost = np.array([detected_ball[0], detected_ball[1], 0, 0], np.float32)  # Initialize at first detected position\n",
        "        initial_kalman_initialized = True\n",
        "\n",
        "    # If the ball is detected, update Kalman Filter\n",
        "    if detected_ball:\n",
        "        kalman.correct(np.array([detected_ball[0], detected_ball[1]], np.float32))\n",
        "        predicted = kalman.predict()\n",
        "        predicted_x, predicted_y = int(predicted[0]), int(predicted[1])\n",
        "\n",
        "        # Calculate speed (in pixels per frame)\n",
        "        if last_position:\n",
        "            dt = 1 / fps  # Time difference between frames (in seconds)\n",
        "            dx = predicted_x - last_position[0]\n",
        "            dy = predicted_y - last_position[1]\n",
        "            speed = np.sqrt(dx**2 + dy**2) / dt  # Speed in pixels per second\n",
        "\n",
        "        # Draw the predicted position\n",
        "        cv2.circle(frame, (predicted_x, predicted_y), 10, (0, 0, 255), -1)\n",
        "        cv2.putText(frame, f\"Predicted Position\", (predicted_x - 20, predicted_y - 20),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "        cv2.putText(frame, f\"Speed: {speed:.2f} px/s\", (predicted_x - 20, predicted_y + 20),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "    else:\n",
        "        predicted = kalman.predict()\n",
        "        predicted_x, predicted_y = int(predicted[0]), int(predicted[1])\n",
        "\n",
        "    # Add the predicted position to the trajectory list\n",
        "    trajectory.append((predicted_x, predicted_y))\n",
        "\n",
        "    # Draw the trajectory (line through all previous positions)\n",
        "    if len(trajectory) > 1:\n",
        "        for i in range(1, len(trajectory)):\n",
        "            cv2.line(frame, trajectory[i-1], trajectory[i], (255, 0, 0), 2)  # Blue line for trajectory\n",
        "\n",
        "    # Write the processed frame (with both YOLO and Kalman Filter tracking)\n",
        "    out.write(frame)\n",
        "\n",
        "    # Optionally show the frame for debugging\n",
        "    cv2_imshow(frame)  # Use cv2_imshow in Colab instead of cv2.imshow()\n",
        "\n",
        "    last_position = (predicted_x, predicted_y)\n",
        "    frame_count += 1\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Eexgh93tJpH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to save the final image showing the trajectory, you can use the last frame or any frame you like\n",
        "if frame is not None:\n",
        "    final_frame = frame.copy()\n",
        "    # Optionally, save a single frame showing the trajectory\n",
        "    cv2.imwrite('/content/drive/MyDrive/tennis_ball_trajectory_final_v5.jpg', final_frame)\n",
        "\n",
        "print(f\"Processed {frame_count} frames. Output video saved to: {output_video_path}\")"
      ],
      "metadata": {
        "id": "r6ikNoXJugMz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}